by Dr. Jeffrey Lewis, Silver Seek : 
The Illusion of Explanatory Depth 
For years I have calmly, patiently, and for the most part rationally, listened to friends, family, patients, and colleagues grapple with the notion of precious metals. 
The majority understand the basic reasons why some portion of portfolio allocation is necessary or prudent, but very few have (or will) taken action. 
Often, people are shocked that I would be interested in the matter to begin with. I think subconsciously people understand to be a “Doctor” is to be a teacher, but on the surface most people find it odd and uncomfortable to accept my interest and quest in something that rarely occurs to them. 
Occasionally, there will be debate. I don’t necessarily look for them. Experience with humans of all ages and from all walks of life has afforded me a healthy dose of humility. But I’m happy and proud to go as far as anyone would like about money, finance and especially silver. 
No matter how tempting it is, no matter how strong the need is to be right and to feel vindicated, it is normally fruitless. I don’t know where I first heard it, but one of my favorite expressions has become: 
“I can explain it to you, but I can’t understand it for you.” 
Understanding requires a shift. One that, I feel myself almost cringing to admit, involves emotional intelligence. This goes against all rational logic. 
Most people are polite. And I’ll admit to a tendency for avoiding conflict — especially given the context in which many of these (potential) debates typically arise. 
I came across the following article by accident some time back . It immediately resonated with my own experience in wrestling with my own beliefs, but also the beliefs, world views, and opinions of people I care about. 
And collectively speaking, the opinions and views of anyone with a pulse who cares about financial safety, justice, and wealth. 
You are, I’m afraid to say, mistaken. The position you are taking makes no logical sense. Just listen up and I’ll be more than happy to elaborate on the many, many reasons why I’m right and you are wrong. Are you feeling ready to be convinced? 
Whether the subject is climate engineering, the Middle East or forthcoming holiday plans, this is the approach many of us adopt when we try to convince others to change their minds. It’s also an approach that, more often than not, leads to the person on the receiving end hardening their existing position. 
(Ed. For the subject of money and wealth, at the root lies the fear of loss – more powerful than the want of profit. People will do anything, and convince themselves of practically anything, to avoid loss.) 
Fortunately, research suggests there is a better way – one that involves more listening and less trying to bludgeon your opponent into submission. 
A little over a decade ago Leonid Rozenblit and Frank Keil from Yale University suggested that in many instances people believe they understand how something works when in fact their understanding is superficial at best. 
They called this phenomenon “the illusion of explanatory depth”. 
They began by asking their study participants to rate how well they understood how things like flushing toilets, car speedometers and sewing machines worked before asking them to explain what they understood and then answer questions on it. 
The effect they revealed was that, on average, people in the experiment rated their understanding as much worse after it had been put to the test. 
What happens, argued the researchers, is that we mistake our familiarity with these things for the belief that we have a detailed understanding of how they work. 
(I’m sure you’ve experienced this with the topic of money and currency. We use the terms interchangeably, though they are very different in reality. I’ll never forget the transformation I witnessed in a “Bitcoin aficionado” – arriving from the technological side of things – coming to grips with the store of wealth versus currency.) 
Usually, nobody tests us and if we have any questions about them we can just take a look. Psychologists call this idea that humans have a tendency to take mental shortcuts when making decisions or assessments the “cognitive miser” theory. 
Why would we bother expending the effort to really understand things when we can get by without doing so? The interesting thing is that we manage to hide from ourselves exactly how shallow our understanding is. 
It’s a phenomenon that will be familiar to anyone who has ever had to teach something. Usually, it only takes the first moments when you start to rehearse what you’ll say to explain a topic (or worse, the first student question) for you to realize that you don’t truly understand it. 
All over the world, teachers say to each other “I didn’t really understand this until I had to teach it.” Or as researcher and inventor Mark Changizi quipped: “I find that no matter how badly I teach I still learn something.” 
Explain Yourself 
Research published last year on this illusion of understanding shows how the effect might be used to convince others they are wrong. 
The research team, led by Philip Fernbach of the University of Colorado, reasoned that the phenomenon might hold as much for political understanding as for things like how toilets work. 
Perhaps, they figured, people who have strong political opinions would be more open to other viewpoints, if asked to explain exactly how they thought the policy they were advocating would bring about the effects they claimed it would. 
Recruiting a sample of Americans via the internet, they polled participants on a set of contentious U.S. policy issues, such as imposing sanctions on Iran, healthcare and approaches to carbon emissions. 
One group was asked to give their opinion and then provide reasons for why they held that view. This group got the opportunity to put their side of the issue, in the same way anyone in an argument or debate has a chance to argue their case. 
Those in the second group did something subtly different. Rather than provide reasons, they were asked to explain how the policy they were advocating would work. They were asked to trace, step by step, from start to finish, the causal path from the policy to the effects it was supposed to have. 
The results were clear. People who provided reasons remained as convinced of their positions as they had been before the experiment. Those who were asked to provide explanations softened their views, and reported a correspondingly larger drop in how they rated their understanding of the issues.